{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4109c32a-29c6-4b23-a6aa-76c5aae47927",
   "metadata": {},
   "source": [
    "<a href=\"https://isaic.ece.ualberta.ca/\"> <center><img src=\"img/index.png\" alt=\"Header\" style=\"width: 200px;\"/></center> </a>\n",
    "\n",
    "> # Accelerated Python Programming using Numba\n",
    ">\n",
    "> **Presentor:** Industry Sandbox and AI Computing (ISAIC)\n",
    ">\n",
    "> **Date:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be18600-2efe-47d3-b263-b58767bc93d3",
   "metadata": {},
   "source": [
    "- **[Numba](http://numba.pydata.org/)** is a just-in-time python function compiler that accelerates numerically-focused python functions for both CPUs and GPUs. Numba uses a collection of decorators that apply on python functions when called for execution. The compiler converts normal python functions to (usually) faster python functions in machine code.\n",
    "\n",
    "- **How does Numba work?**\n",
    "\n",
    "<center><img src=\"img/numba1.PNG\" alt=\"Header\" style=\"width: 400px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490ec97",
   "metadata": {},
   "source": [
    "## Introduction to Numba for CPU\n",
    "\n",
    "The most fundamental decorator to compile python functions is `@jit`. Let's see how it works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ed4a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import math\n",
    "\n",
    "# This is the function decorator syntax and is equivalent to `doublegauss = jit(doublegauss)`.\n",
    "# The Numba compiler is just a function you can call whenever you want!\n",
    "@jit\n",
    "def doublegauss(x, y):\n",
    "    '''For given x and y values, computes the gaussian function'''\n",
    "    #the following few lines are redundant, but used to keep the computation a bit more lengthy\n",
    "    x = abs(x)\n",
    "    y = abs(y)\n",
    "    t1 = x*x\n",
    "    t2 = y*y\n",
    "    val = math.exp(-t1-t2)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee71d0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006737946999085467"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compiler converts python function into machine code\n",
    "doublegauss(1,2)\n",
    "\n",
    "#numba also saves the original python function\n",
    "doublegauss.py_func(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4ca74d-ea58-4f64-8c8b-9761cd904ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph \"CFG for '_ZN8__main__15doublegauss_241B46c8tJTIeFCjyCbUFRqqOAFv_2fYRdE1AT0EZmkCAA_3d_3dExx' function\" {\n",
      "\tlabel=\"CFG for '_ZN8__main__15doublegauss_241B46c8tJTIeFCjyCbUFRqqOAFv_2fYRdE1AT0EZmkCAA_3d_3dExx' function\";\n",
      "\n",
      "\tNode0x5640e2c7f1b0 [shape=record,label=\"{entry:\\l  %.13 = mul i64 %arg.y, %arg.y\\l  %0 = mul i64 %arg.x, %arg.x\\l  %.14 = sub i64 0, %0\\l  %.15 = sub nsw i64 %.14, %.13\\l  %.16 = sitofp i64 %.15 to double\\l  %.17 = tail call double @llvm.exp.f64(double %.16)\\l  store double %.17, double* %retptr, align 8\\l  ret i32 0\\l}\"];\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#let's see how the control-flow graph object looks like\n",
    "print (doublegauss.inspect_cfg(doublegauss.signatures[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af0b35",
   "metadata": {},
   "source": [
    "- **Benchmarking runtime:**\n",
    "\n",
    "In order to validate how effective Numba compiler is, we need to measure the performance of each run of the code. For this we will use `%timeit` magic function that computes the runtime many times and reports an average value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f887a3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 ns ± 0.203 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "#use the magic function %timeit\n",
    "\n",
    "#for original python function implementation\n",
    "%timeit doublegauss.py_func(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f49fd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232 ns ± 0.183 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "#for numba compiled python function\n",
    "%timeit doublegauss(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdbb8e7-a066-43b2-9b35-ab77756fd848",
   "metadata": {},
   "source": [
    "We see that numba is already faster on CPU compared to usual python function run. This is because, once the numba compiler finished compiling the python function into machine code, it re-uses the pre-compiled object to execute without any overhead. Where as, the usual python function compiler starts compiling from scratch everytime the function is called."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31689cfc",
   "metadata": {},
   "source": [
    "- **A bit more heavier task in python function**\n",
    "\n",
    "Although we have seen a slight improvement, our function is too simple to draw any significant conclusion from the above example.\n",
    "\n",
    "Let's look into another function example that uses a heavier computational task.\n",
    "\n",
    "In this example, we will use Monte Carlo method to determine the value of Pi. The way we do this is by drawing two random numbers independently between [0,1] and check if the point lies inside 1/4th of a circle with unit radius. The diagram below visualizes the problem of calculating value of Pi:\n",
    "\n",
    "<center><img src=\"img/mc.PNG\" alt=\"Header\" style=\"width: 400px;\"/></center>\n",
    "\n",
    "Now higher the number of random (x,y) samples we draw, the more precise value of Pi we will get. Also the computation work increases with the increase of the number of the random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cae4a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the number of (x,y) samples to draw\n",
    "nsamples = 1000000\n",
    "\n",
    "import random\n",
    "\n",
    "@jit\n",
    "def monte_carlo_pi(nsamples):\n",
    "    ''' Calculates the value of Pi'''\n",
    "    #counter for the points that lie within the circle\n",
    "    acc = 0\n",
    "    #iterate over the number of samples\n",
    "    for i in range(nsamples):\n",
    "        #draw independent random samples everytime\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        #check if the point lies within the circle\n",
    "        if (x**2 + y**2) < 1.0:\n",
    "            acc += 1\n",
    "    return 4.0 * acc / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aa67b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.9 ms ± 1.15 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit monte_carlo_pi(nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94671428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394 ms ± 604 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit monte_carlo_pi.py_func(nsamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ee31fa-21bb-430f-997f-a7b39a0bdb8b",
   "metadata": {},
   "source": [
    "That's more than **30 times faster** than normal python compiler! So just by adding single line of Numba decorator can increase the performance of python computation significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4106c2",
   "metadata": {},
   "source": [
    "- **Limited data type support:**\n",
    "\n",
    "Numba doesn't support certain data types, (e.g. dictionaries). However by default, numba falls back to python **object mode** in such scenarios. To force implement numba compilation, we can use additional argument in the decorator `nopython=True` to force run in **nopython mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f744133d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_277036/324830447.py:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"dict_func\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at /tmp/ipykernel_277036/324830447.py (3)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"../../../tmp/ipykernel_277036/324830447.py\", line 3:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "/opt/tljh/user/lib/python3.9/site-packages/numba/core/object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"dict_func\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"../../../tmp/ipykernel_277036/324830447.py\", line 1:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "/opt/tljh/user/lib/python3.9/site-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"../../../tmp/ipykernel_277036/324830447.py\", line 1:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'value'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jit\n",
    "def dict_func(x):\n",
    "    return x['key']\n",
    "\n",
    "#without mode specification, it will only give a warning message\n",
    "#but will the run the function after falling back to object mode\n",
    "\n",
    "dict_func(dict(key='value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94b26776",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of argument at /tmp/ipykernel_277036/3933219848.py (3)\u001b[0m\n\u001b[1m\nFile \"../../../tmp/ipykernel_277036/3933219848.py\", line 3:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m \n\nThis error may have been caused by the following argument(s):\n- argument 0: \u001b[1mCannot determine Numba type of <class 'dict'>\u001b[0m\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_277036/3933219848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#since here we have specified to run in nopython mode, any given non-supported data type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#in function argument will raise error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdict_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    466\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0merror_rewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'typing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;31m# Something unsupported is present in the user code, add help info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of argument at /tmp/ipykernel_277036/3933219848.py (3)\u001b[0m\n\u001b[1m\nFile \"../../../tmp/ipykernel_277036/3933219848.py\", line 3:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m \n\nThis error may have been caused by the following argument(s):\n- argument 0: \u001b[1mCannot determine Numba type of <class 'dict'>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "@jit(nopython=True)\n",
    "def dict_func(x):\n",
    "    return x['key']\n",
    "\n",
    "#since here we have specified to run in nopython mode, any given non-supported data type\n",
    "#in function argument will raise error.\n",
    "dict_func(dict(key='value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e1c700-08f6-4c5f-b8c4-84a7fabb90c6",
   "metadata": {},
   "source": [
    "While using Numba compiler for acceleration purpose, it is good practice to force run with `nopython` as it will ensure the implementation of Numba compilation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c634f",
   "metadata": {},
   "source": [
    "## Numpy ufuncs computation on GPUs\n",
    "\n",
    "GPU hardware is designed for *data parallelism*. Full potential is achieved when the GPU is computing the same operations on sufficiently large number of elements at once.\n",
    "\n",
    "NumPy Universal functions (ufuncs) (e.g. `np.add`, `np.multiply` etc), which perform the same operation on every element in a NumPy array, are naturally data parallel, so they are a natural fit for GPU programming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b99f8c",
   "metadata": {},
   "source": [
    "- **Some Terminology:**\n",
    "\n",
    "Before we proceed further, let's introduce some terms that we will frequently use for the rest of the tutorial.\n",
    "\n",
    "    - host : CPU\n",
    "    - device : GPU\n",
    "    - host memory : main system memory (RAM)\n",
    "    - device memory : Onboard memory on GPU card (graphics memory)\n",
    "    - kernel : a GPU function launched by the host and executed on the device\n",
    "    - device function : a GPU function executed on the device and can only be called from the device\n",
    "\n",
    "Unfortunately, NumPy in-built ufuncs are inherent to CPU and cannot be compiled with Numba. However, we can create our own ufunc using Numba compiler. We first create a python scalar function and then decorate it with Numba `vectorize`.\n",
    "\n",
    "In this example we will use the `@vectorize` decorator to compile and optimize a ufunc for the CPU first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "feece780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import vectorize\n",
    "\n",
    "@vectorize\n",
    "def mult_ten(x):\n",
    "    '''takes a scaler value x and mutliplies by 10'''\n",
    "    return x*10\n",
    "#the scalar value x operation will be performed on each numpy element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b66a1853-3581-4bc7-85b7-4f2a231e7542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(10)\n",
    "\n",
    "mult_ten(arr)#passing the whole array to the python function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70e8875-4066-4a1a-84e1-c45e2b6d223b",
   "metadata": {},
   "source": [
    "- **Compiling on CUDA**\n",
    "\n",
    "Let us now generate a ufunc that uses CUDA on the GPU with the addition of giving an **explicit type signature** and setting the `target` attribute. The type signature argument describes what types to use both for the ufuncs arguments and return value:\n",
    "```python\n",
    "'return_value_type(argument1_value_type, argument2_value_type, ...)'\n",
    "```\n",
    "\n",
    "Please see the Numba docs for more on [available types](https://numba.pydata.org/numba-doc/dev/reference/types.html), as well as for additional information on [writing ufuncs with more than one signature](https://numba.pydata.org/numba-doc/dev/user/vectorize.html)\n",
    "\n",
    "Here is a simple example of a ufunc that will be compiled for a CUDA enabled GPU device. It expects two `int64` values and return also an `int64` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecb55e8d-1916-47f5-9cc8-00bd460a5cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize(['int64(int64, int64)'], target='cuda') # Type signature and target are required for the GPU\n",
    "def mult_func(x,y):\n",
    "    return x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adab3ca0-124c-4d4d-99b8-b857fad85e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.9/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: \u001b[1mGrid size (1) < 2 * SM count (160) will likely result in GPU under utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 10,  40,  90, 160, 250, 360])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5,6])\n",
    "b = np.array([10,20,30,40,50,60])\n",
    "mult_func(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f6461-6b8e-4be1-984c-0b063875b609",
   "metadata": {},
   "source": [
    "After calling numba gpu function,  Numba just automatically executed the follwoing steps in sequence:\n",
    "\n",
    " * Compiled a CUDA kernel to execute the ufunc operation in parallel over all the input elements.\n",
    " * Allocated GPU memory for the inputs and the output.\n",
    " * Copied the input data to the GPU.\n",
    " * Executed the CUDA kernel (GPU function) with the correct kernel dimensions given the input sizes.\n",
    " * Copied the result back from the GPU to the CPU.\n",
    " * Returned the result as a NumPy array on the host.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d643ee",
   "metadata": {},
   "source": [
    "**Side note:** Taking a look at the data types can sometimes be important in GPU code because the performance of `float32` (single precision) and `float64` (double precision) computations can (depending on the GPU) be very different on CUDA devices. If your algorithm can obtain correct results using `float32`, then you should probably use that data type, because casting to `float64` can, depending on the GPU type, dramatically slow down the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e466ef-0857-4511-9e30-28274fe8c40a",
   "metadata": {},
   "source": [
    "- **Benchmarking the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "262e0bee-277c-43e4-a139-cdff292d783d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497 ns ± 0.0933 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "#in-built numpy function\n",
    "%timeit np.multiply(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "111055c2-8057-4623-a53f-13be1204961e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.06 ms ± 1.58 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "#numbe compiled function executed on GPU\n",
    "%timeit mult_func(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533e85ba-a981-4b0c-b00e-e3478a422995",
   "metadata": {},
   "source": [
    "The GPU function is **a lot slower** than the CPU! For this example, it is expected as we have misused GPU in several ways:\n",
    "\n",
    "- Inputs are too small (cause for the above warning message)\n",
    "- Calculation is too simple\n",
    "- Data is copied to and from the GPU\n",
    "- Data types are larger than necessary\n",
    "\n",
    "It is important to understand which problems are well suited for GPU. Let us now try an example that is more intense in computation and actually faster in the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6abfee05-f246-4d8c-afec-84209aad9d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math # Note that for the CUDA target, we need to use the scalar functions from the math module, not NumPy\n",
    "\n",
    "SQRT_2PI = np.float32((2*math.pi)**0.5)  # Precompute this constant as a float32.\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32)'], target='cuda')\n",
    "def gaussian_pdf(x, mean, sigma):\n",
    "    '''Compute the value of a Gaussian probability density function at x with given mean and sigma.'''\n",
    "    return math.exp(-0.5 * ((x - mean) / sigma)**2) / (sigma * SQRT_2PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "653c991c-e13e-415e-a008-62f32a851f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.9/site-packages/numba/cuda/compiler.py:726: NumbaPerformanceWarning: \u001b[1mGrid size (1) < 2 * SM count (160) will likely result in GPU under utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.0138177])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Evaluate the Gaussian a million times!\n",
    "x = np.random.uniform(-3, 3, size=100000000).astype(np.float32)\n",
    "mean = np.float32(0.0)\n",
    "sigma = np.float32(1.0)\n",
    "\n",
    "# Quick test on a single element just to make sure it works\n",
    "gaussian_pdf(x[0], 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23438140-2133-4065-8a07-620e8482cce9",
   "metadata": {},
   "source": [
    "Note that we are still getting the warning message even after using large array `x` is because, when we called `gaussian_pdf` above it only used a single value from the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4648cf6-4792-4efa-b53b-c21e25205a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.64 s ± 4.19 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats # for definition of gaussian distribution, so we can compare CPU to GPU time\n",
    "norm_pdf = scipy.stats.norm\n",
    "%timeit norm_pdf.pdf(x, loc=mean, scale=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ab3efc5-b043-4098-bebe-adbda3a009bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470 ms ± 30.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit gaussian_pdf(x, mean, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2344529e-ff09-4eed-b957-c434f244b909",
   "metadata": {},
   "source": [
    "This is a big improvement (almost **10 times faster**). To compare with compiled CPU version, let's define the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3103b17b-6f3c-42f6-9ce5-6220aa7030b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize\n",
    "def cpu_gaussian_pdf(x, mean, sigma):\n",
    "    '''Compute the value of a Gaussian probability density function at x with given mean and sigma.'''\n",
    "    return math.exp(-0.5 * ((x - mean) / sigma)**2) / (sigma * SQRT_2PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d321f6f-3ac6-4a5b-bada-b908237a16d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.48 s ± 4.45 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit cpu_gaussian_pdf(x, mean, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce39302-de20-44f1-b9a8-1a2be1b39c19",
   "metadata": {},
   "source": [
    "**Comparision:**\n",
    "\n",
    "- Uncompiled CPU scipy function: 4.6 s ± 5.41 ms\n",
    "- Compiled custom CPU function: 1.48 s ± 4.45 ms\n",
    "- Compiled GPU function: 460 ms ± 27.3 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45be26e-7dd5-4a23-ad0e-d53df98f9b4b",
   "metadata": {},
   "source": [
    "## CUDA Device functions\n",
    "\n",
    "To compile functions for the GPU that are **not** element wise, vectorized functions, we use `numba.cuda.jit`. Let's now see how to use it to decorate a helper function, to be utilized by a GPU accelerated ufunc, so that we are not required to write all our logic into a single ufunc defintion or having to write separate unfuncs with detailed decorator everytime.\n",
    "\n",
    "Notice that `polar_to_cartesian` below does not require a type signature, and also, that it is passed two scalar values, unlike the vectorized ufuncs we have been using (and like `polar_distance` below) which expect NumPy arrays as arguments.\n",
    "\n",
    "The argument `device=True` indicates that the decorated function can **only** be called from a function running on the GPU, and not from CPU host code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f15cbc1e-ffd8-4809-924c-49d2f0e6d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def polar_to_cartesian(rho, theta):\n",
    "    x = rho * math.cos(theta)\n",
    "    y = rho * math.sin(theta)\n",
    "    return x, y\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32, float32)'], target='cuda')\n",
    "def polar_distance(rho1, theta1, rho2, theta2):\n",
    "    x1, y1 = polar_to_cartesian(rho1, theta1) # We can use device functions inside our GPU ufuncs\n",
    "    x2, y2 = polar_to_cartesian(rho2, theta2)\n",
    "    \n",
    "    return ((x1 - x2)**2 + (y1 - y2)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bb4b4c8-ebc6-4a89-ae06-9becba69475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000000\n",
    "rho1 = np.random.uniform(0.5, 1.5, size=n).astype(np.float32)\n",
    "theta1 = np.random.uniform(-np.pi, np.pi, size=n).astype(np.float32)\n",
    "rho2 = np.random.uniform(0.5, 1.5, size=n).astype(np.float32)\n",
    "theta2 = np.random.uniform(-np.pi, np.pi, size=n).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f2247a2-9af2-443c-b349-bab22afa604d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52712027, 0.68070417, 1.92223535, ..., 1.18200532, 1.54287882,\n",
       "       2.079705  ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polar_distance(rho1, theta1, rho2, theta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822d3e98-0081-46e9-9664-87ace3994439",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Optimizing GPU memory utilization\n",
    "\n",
    "So far we have used NumPy arrays on the CPU as inputs and outputs to our GPU functions. Numba has been automatically transferring this data to the GPU for us so that it can be operated on by the GPU. With this implicit data transfer Numba, acting conservatively, will automatically transfer the data back to the CPU after processing. This process is a time intensive operation and can be a bottle neck of the computation.\n",
    "\n",
    "So our goal is to **minimiza the data transfer between the host (CPU) and the device (GPU)**\n",
    "\n",
    "In order to implement this, we need to prevent Numba's automatic data transfer and manually copying it back to the host when all the operations ar done.\n",
    "\n",
    "The way to do this is to create **CUDA Device Arrays** and pass them to our GPU functions. Device arrays will not be automatically transfered back to the host after processing, and can be reused as we wish on the device before ultimately, and only if necessary, sending them, or parts of them, back to the host.\n",
    "\n",
    "To demonstrate, let's create our example addition ufunc again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb2c6a86-2493-4e09-900c-8b9ced5703a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize(['float32(float32, float32)'], target='cuda')\n",
    "def mult_func(x, y):\n",
    "    return x * y\n",
    "\n",
    "n = 1000000\n",
    "x = np.arange(n).astype(np.float32)\n",
    "y = 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6bb6c46-03e3-4805-b69a-39f7ebffa905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.69 ms ± 48.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mult_func(x, y)  # Baseline performance with host arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb59d88d-0b58-4fae-ba5a-d704d5e39672",
   "metadata": {},
   "source": [
    "The `numba.cuda` module includes a function that will copy host data to the GPU and return a CUDA device array. Note that below when we try to print the content of the device array, we only get information about the array, and not its actual contents. This is because the data is on the device, and we would need to transfer it back to the host in order to print its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2791a72c-62af-49d2-9c4a-1462f0880a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7fea1c4fd4c0>\n",
      "(100000,)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "\n",
    "x_device = cuda.to_device(x)\n",
    "y_device = cuda.to_device(y)\n",
    "\n",
    "print(x_device)\n",
    "print(x_device.shape)\n",
    "print(x_device.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "930bd7ec-4f1b-4d18-96ac-a52312a633e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902 µs ± 2.96 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "#Device arrays can be passed to CUDA functions just like NumPy arrays\n",
    "%timeit mult_func(x_device, y_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1f2164-b876-44e0-88cd-2182e868b0e6",
   "metadata": {},
   "source": [
    "Because x_device and y_device are already on the device, this benchmark is much faster (almost **2 times**).\n",
    "\n",
    "Note that, if we don't assign the output into a variable, it gets sent back to the host CPU. On the other hand, if the output is assigned into a variable, it stays as CUDA device array. In order to do this, we can initialize a CUDA output array and pass it as the output variable when calling the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a432ebe5-897a-4d62-955a-c7d1ac329d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737 µs ± 650 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "out_device = cuda.device_array(shape=(n,), dtype=np.float32)  # does not initialize the contents, like np.empty()\n",
    "%timeit mult_func(x_device, y_device, out=out_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d7c165-381c-44d7-aea5-7aa78085a4e8",
   "metadata": {},
   "source": [
    "When we want to bring a device array back to the host memory, we can use the `copy_to_host()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "957eff29-060f-46b0-92e7-3436b33360c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   2.   8.  18.  32.  50.  72.  98. 128. 162.]\n"
     ]
    }
   ],
   "source": [
    "out_host = out_device.copy_to_host()\n",
    "print(out_host[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4473384-ba07-4aa7-b1e9-abf291d76343",
   "metadata": {},
   "source": [
    "## Accelarating Neural Network Computation on GPU\n",
    "\n",
    "Now that we know how to perform python function calculations on GPU in a memory optimized way, let's implement a hidden layer neural network calculation accelarated on GPU.\n",
    "\n",
    "A hidden layer operation in our example consists of normalizing grey scale values, weighting each input for the linear transformation and applies activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5af7e75-0fe7-4e45-92ec-b69f796cb537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our hidden layer will contain 1M neurons.\n",
    "n = 1000000\n",
    "\n",
    "greyscales = np.floor(np.random.uniform(0, 255, n).astype(np.float32))\n",
    "weights = np.random.normal(.5, .1, n).astype(np.float32)\n",
    "\n",
    "from math import exp\n",
    "\n",
    "\n",
    "@vectorize(['float32(float32)'], target='cuda')\n",
    "def normalize(grayscales):\n",
    "    return grayscales / 255\n",
    "\n",
    "@vectorize(['float32(float32, float32)'], target='cuda')\n",
    "def weigh(values, weights):\n",
    "    return values * weights\n",
    "        \n",
    "@vectorize(['float32(float32)'], target='cuda')\n",
    "def activate(values):\n",
    "    return ( exp(values) - exp(-values) ) / ( exp(values) + exp(-values) )\n",
    "\n",
    "\n",
    "#here we can define a usual python function and call GPU-accelerated ufuncs inside\n",
    "def create_hidden_layer(n, greyscales, weights, exp, normalize, weigh, activate):\n",
    "    \n",
    "    #first convert the host arrays to device array\n",
    "    grey_device = cuda.to_device(greyscales)\n",
    "    weight_device = cuda.to_device(weights)\n",
    "\n",
    "    #assign an empty device array for output\n",
    "    norm_out = cuda.device_array(shape=(n,), dtype=np.float32)\n",
    "    normalize(grey_device, out=norm_out)\n",
    "    \n",
    "    #\n",
    "    weight_out = cuda.device_array(shape=(n,), dtype=np.float32)\n",
    "    weigh(norm_out, weight_device, out=weight_out)\n",
    "    \n",
    "    activated = activate(weight_out)\n",
    "    activated = activated.copy_to_host()\n",
    "    \n",
    "    return activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81f270fc-9e9b-4c13-a8d9-265d9c11eb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.54 ms ± 88.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit create_hidden_layer(n, greyscales, weights, exp, normalize, weigh, activate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da90b52d-f49e-4f79-8197-363f0e60f617",
   "metadata": {},
   "source": [
    "## Bonus: Writing Custom CUDA Kernel\n",
    "\n",
    "So far we know how to use GPU-accelerated ufuncs, device functions and optimize data movement too speed up our code. The vectorized GPU-accelerated python functions are a type of CUDA kernels that automatically distributes the parallel computing on the device based on the size of the data array. However, in reality our problems do not always consists of only universal array functions. For example, in our last example, to apply different GPU-accelerated ufuncs we needed to write a normal python function that executes on the host and sends inner gpu functions to the device. We can improve this implementation by writing the entire above python function as CUDA kernel and execute the entire code on the device.\n",
    "\n",
    "Another important aspect of writing our own custom CUDA kernel is that we can manage the parallel computing distribution ourselves via **execution configuration** which CUDA kernels require during its run. To understand how to configure CUDA kernel execution, let's look into the following diagram:\n",
    "\n",
    "<center><img src=\"img/cuda.PNG\" alt=\"Header\" style=\"width: 400px;\"/></center>\n",
    "\n",
    "- **Thread Hierarchy**\n",
    "\n",
    "When we launch a GPU function (CUDA kernel) it runs on many **threads** in parallel. A collection of threads forms a **block**. A CUDA kernel can run on several blocks, and for a given launch, the collection of all the blocks associated form a **grid**. When we launch a kernel with execution configuration, it defines the *number of blocks* in the grid and *number of threads* in each block. CUDA and Numba together provides some thread hierarchy variables that we can use while writing our kernel. The idea is to somehow map the **index of each element** in the dataset array to the **index of each thread** in the grid, so when we launch the kernel it processes elements of the dataset in threads in parallel. Let's now look at these variables:\n",
    "\n",
    "- `gridDim.x` : number of blocks in the grid\n",
    "- `blockIdx.x` : index of the current block within the grid (starts with 0)\n",
    "- `blockDim.x` : number of threads in a block (all blocks contain the same number of threads in a grid)\n",
    "- `threadIdx.x` : index of the current thread within a block (starts with 0 in each block)\n",
    "- `cuda.grid()` : Numba provides unique thread index using the formula: `threadIdx.x + blockIdx.x * blockDim.x`\n",
    "- `cuda.gridsize()` : Numba provided variable that returns the total number of threads in the grid, i.e. `gridDim.x * blockDim.x`\n",
    "\n",
    "Using the above variables, we can now coordinate the parallel cmputing by mapping the dataset element index to unique thread index. Let's see how we can implement out first CUDA kernel..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de3d3b65-267f-4516-a459-d442c4e00711",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from math import exp\n",
    "\n",
    "#convert the previously used GPU vectorized functions into device functions\n",
    "@cuda.jit(device=True)\n",
    "def normalize(grayscales):\n",
    "    return grayscales / 255\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def weigh(values, weights):\n",
    "    return values * weights\n",
    "        \n",
    "@cuda.jit(device=True)\n",
    "def activate(values):\n",
    "    return ( exp(values) - exp(-values) ) / ( exp(values) + exp(-values) )\n",
    "\n",
    "\n",
    "#here we can define the CUDA kernel\n",
    "\n",
    "#CUDA kernel does NOT return anything, instead we provide an empty outut array in the function\n",
    "#input argument\n",
    "\n",
    "@cuda.jit\n",
    "def create_hidden_layer_kernel(greyscales, weights, out_array):\n",
    "\n",
    "    #here the variable extracts the current thread's index\n",
    "    start_idx = cuda.grid(1)\n",
    "    #here we extract the total number of threads in the grid\n",
    "    stride = cuda.gridsize(1)\n",
    "    \n",
    "    #here we implement grid strid loop, i.e. the current thread works on data elements\n",
    "    #in the dataset starting from start index and jumping every stride number of elements\n",
    "    #to work on the next element until there's no more element left in the dataset\n",
    "    for idx in range(start_idx, greyscales.shape[0], stride):\n",
    "        out_array[idx] = activate(weigh(normalize(greyscales[idx]), weights[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "021abbe8-895a-424e-8d46-1f3bb8b75070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Managed Device 0>, <Managed Device 1>\n"
     ]
    }
   ],
   "source": [
    "#check the GPU lists\n",
    "print (cuda.gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c5725ae-321a-4382-9870-b3991db8b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our hidden layer will contain 1M neurons.\n",
    "n = 1000000\n",
    "\n",
    "#setting the arrays\n",
    "greyscales = np.floor(np.random.uniform(0, 255, n).astype(np.float32))\n",
    "weights = np.random.normal(.5, .1, n).astype(np.float32)\n",
    "\n",
    "greyscales_d = cuda.to_device(greyscales)\n",
    "weights_d = cuda.to_device(weights)\n",
    "\n",
    "out = cuda.device_array_like(greyscales_d)\n",
    "\n",
    "threads_per_block = 128\n",
    "blocks_per_grid = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ced29b4a-eaaf-4c3e-b41b-aa89e2b6e5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858 µs ± 157 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "[0.5060845  0.12321589 0.35860813 ... 0.10897925 0.34099004 0.40804127]\n"
     ]
    }
   ],
   "source": [
    "%timeit create_hidden_layer_kernel[blocks_per_grid, threads_per_block](greyscales_d, weights_d, out); cuda.synchronize()\n",
    "print (out.copy_to_host())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83353083-ba26-4413-9ce8-f0ea8ea0c2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
